import express from "express";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { loadVectorStore } from "../utils/vectorStoreLoader.js";
import { HumanMessage, AIMessage } from "@langchain/core/messages";
import { config as configDotenv } from "dotenv";

configDotenv();

const router = express.Router();

const model = new ChatGoogleGenerativeAI({
Â  model: process.env.GOOGLE_MODEL || "gemini-1.5-flash",
Â  apiKey: process.env.GOOGLE_API_KEY2,
});

const simpleRoutes = {
Â  "hi": "I am Hamilton AI, here to give you information on Lewis Hamilton. How can I help?",
Â  "hello": "I am Hamilton AI, here to give you information on Lewis Hamilton. How can I help?",
Â  "hey": "I am Hamilton AI, here to give you information on Lewis Hamilton. How can I help?",
Â  "sup": "I am Hamilton AI, here to give you information on Lewis Hamilton. How can I help?",
Â  "what up": "I am Hamilton AI, here to give you information on Lewis Hamilton. How can I help?",
Â  "who are you": "I am Hamilton AI, a chatbot designed to provide information about the life and career of Lewis Hamilton.",
Â  "what are you": "I am Hamilton AI, a chatbot designed to provide information about the life and career of Lewis Hamilton.",
};

// We don't need the simple pronoun regex anymore, the LLM will handle it.
// const pronounRegex = /\b(he|him|his)\b/i;

router.post("/", async (req, res) => {
Â  try {
Â  Â  const { query, history = [] } = req.body;

Â  Â  if (!query) {
Â  Â  Â  return res.status(400).json({ error: "Query is required" });
Â  Â  }

Â  Â  const normalizedQuery = query.toLowerCase().trim();
Â  Â  if (simpleRoutes[normalizedQuery]) {
Â  Â  Â  console.log("âœ… Greeting/Identity route triggered.");
Â  Â  Â  return res.json({ answer: simpleRoutes[normalizedQuery] });
Â  Â  }

Â  Â  let standaloneQuery = query;

    // --- Start of NEW, More Robust Context Resolution ---
    // If there is a chat history, we always try to condense the query.
Â  Â  if (history.length > 0) {
        console.log("ğŸ¤” History detected. Condensing query for context...");

        const chatHistory = history.map(msg => 
          msg.type === 'human' ? new HumanMessage(msg.text) : new AIMessage(msg.text)
        );

        // A single, robust prompt to handle all kinds of follow-ups.
        const condensingPrompt = [
            new HumanMessage(`Given the chat history and a follow-up question, rephrase the follow-up question into a single, standalone question that can be understood without the chat history. If the follow-up question is already standalone, return it as is.

            Chat History:
            human: What year did Lewis Hamilton win his first championship?
            ai: He won his first World Championship in 2008.
            
            Follow-Up Question: What team was he with?
            
            Standalone question:`),
            new AIMessage("What team was Lewis Hamilton with when he won his first championship in 2008?"),

            new HumanMessage(`Chat History:
            human: Who was his teammate in 2007 in mclaren?
            ai: Fernando Alonso.

            Follow-Up Question: in mercedes??
            
            Standalone question:`),
            new AIMessage("Who was Lewis Hamilton's teammate in Mercedes?"),

            new HumanMessage(`Chat History:
            ${chatHistory.map(msg => `${msg.type}: ${msg.text}`).join('\n')}

            Follow-Up Question: ${query}
            
            Standalone question:`),
        ];

        const condensedResponse = await model.invoke(condensingPrompt);
        standaloneQuery = condensedResponse.content.trim();
        
        // Log if the query was changed.
        if (standaloneQuery.toLowerCase() !== query.toLowerCase()) {
            console.log(`âœ¨ Query condensed. Standalone Question: "${standaloneQuery}"`);
        } else {
            console.log("âœ… Query was already standalone.");
        }
Â  Â  }
    // --- End of NEW Context Resolution ---

Â  Â  const vectorStore = await loadVectorStore();
Â  Â  const initialSearchResult = await vectorStore.maxMarginalRelevanceSearch(standaloneQuery, {
Â  Â  Â  k: 1,
Â  Â  Â  fetchK: 5,
Â  Â  });
Â  Â  
Â  Â  const RELEVANCE_THRESHOLD = 0.69; 
Â  Â  let finalPrompt;
Â  Â  let isHamiltonRelated = false;

Â  Â  if (initialSearchResult.length > 0 && initialSearchResult[0][1] >= RELEVANCE_THRESHOLD) {
Â  Â  Â  isHamiltonRelated = true;
Â  Â  Â  console.log(`âœ… Hamilton-related question detected. Score: ${initialSearchResult[0][1].toFixed(3)}`);

Â  Â  Â  const contextResults = await vectorStore.similaritySearch(standaloneQuery, 4);
Â  Â  Â  const context = contextResults
Â  Â  Â  Â  .map((r, i) => `--- Document ${i + 1} ---\n${r.pageContent}`)
Â  Â  Â  Â  .join("\n\n");
Â  Â  Â  
Â  Â  Â  finalPrompt = `
Â  Â  Â  Â  # Your Persona: Lewis Hamilton Expert
Â  Â  Â  Â  You are Hamilton AI. Your answers about Lewis Hamilton MUST be based exclusively on the 'Context'.
Â  Â  Â  Â  Act as if you know this information yourself. Never mention the context or documents.
Â  Â  Â  Â  NO SOURCES OR CITATIONS.
Â  Â  Â  Â  
Â  Â  Â  Â  # Context
Â  Â  Â  Â  ${context}

Â  Â  Â  Â  # Question
Â  Â  Â  Â  ${standaloneQuery}
Â  Â  Â  `;
Â  Â  } else {
Â  Â  Â  isHamiltonRelated = false;
Â  Â  Â  const score = initialSearchResult.length > 0 ? initialSearchResult[0][1].toFixed(3) : "N/A";
Â  Â  Â  console.log(`âŒ Unrelated question detected. Top Score: ${score}`);

Â  Â  Â  finalPrompt = `
Â  Â  Â  Â  # Your Persona: General Knowledge Assistant
Â  Â  Â  Â  You are Hamilton AI, a friendly and helpful AI assistant.
Â  Â  Â  Â  The user has asked a question that is not about your primary subject, Lewis Hamilton.
Â  Â  Â  Â  Provide a full, accurate, and helpful answer to the user's question using your general knowledge.
Â  Â  Â  Â  NO SOURCES OR CITATIONS.

Â  Â  Â  Â  # Question
Â  Â  Â  Â  ${standaloneQuery}
Â  Â  Â  `;
Â  Â  }

Â  Â  const finalResponse = await model.invoke(finalPrompt);

Â  Â  res.json({ 
Â  Â  Â  answer: finalResponse.content,
Â  Â  Â  // We still need this flag for the *next* turn's history.
Â  Â  Â  isHamiltonRelated: isHamiltonRelated 
Â  Â  });

Â  } catch (error) {
Â  Â  console.error("ğŸ’¥ Chat error:", error);
Â  Â  res.status(500).json({ error: "Something went wrong" });
Â  }
});

export default router;